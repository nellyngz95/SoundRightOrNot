title: [Synthetic audio optimization by feature driven importance.]
The perceptual quality of synthetic sound models remains a significant challenge for sound designers, primarily due to the lack of standardized objective evaluation methods and the limited availability of diverse synthetic samples. These limitations complicate the identification of perceptual deficiencies in synthesized audio. While classification models can effectively differentiate between real and synthetic sounds, gaining insight into the underlying decision-making process can reveal which acoustic features need refinement.

In this work, we propose a multiclass classification framework trained on 30 sound categories, which includes both recorded and synthesized samplesâ€”such as applause, fire, explosions, and whooshes. By analyzing the feature importance within the model, we extract interpretable cues that differentiate real audio from synthetic counterparts. These cues are utilized to inform targeted post-production enhancements, such as equalization, reverb, compression, and distortion, all aimed at improving the perceptual quality of synthesized sounds.

Subjective evaluations indicate that modifications suggested by our framework result in perceptual improvements in several categories, particularly applause, fire, bubbles, and explosions. Our findings highlight the potential of feature-driven interpretability to facilitate more transparent and effective optimization of sound models, providing a valuable tool for both evaluation and iterative design in audio synthesis.
